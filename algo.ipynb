{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter support in percentage:40\n",
      "Enter confidence in percentage:100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "while True:\n",
    "    try:\n",
    "        support = float(input('Enter support in percentage:'))\n",
    "        if support < 1 or support > 100:\n",
    "            raise ValueError \n",
    "        break\n",
    "    except ValueError:\n",
    "        print(\"Invalid support value.The number must be in the range of 1-100.\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        confidence = float(input('Enter confidence in percentage:'))\n",
    "        if confidence < 1 or confidence > 100:\n",
    "            raise ValueError \n",
    "        break\n",
    "    except ValueError:\n",
    "        print(\"Invalid confidence. The number must be in the range of 1-100.\")\n",
    "\n",
    "min_support = support/100\n",
    "min_confidence=confidence/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Data From text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Enter number from below to choose database: 1.Amazon, 2.Nike, 3.BestBuy, 4.dataset1,5.KMart5\n",
      "KMart.txt\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        s=int(input(\"'Enter number from below to choose database: 1.Amazon, 2.Nike, 3.BestBuy, 4.dataset1,5.KMart\"))\n",
    "        if s < 1 or s > 5:\n",
    "            raise ValueError \n",
    "        break\n",
    "    except ValueError:\n",
    "        print(\"Invalid support value.The number must be in the range of 1-5.\")\n",
    "\n",
    "dataset_dict= {1:'Amazon.txt',2:'Nike.txt',3:'BestBuy.txt',4:'dataset1.txt',5:'KMart.txt'}\n",
    "path_to_data = dataset_dict[s]\n",
    "print(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transactions(path_to_data):\n",
    "    Transactions = []\n",
    "    order=[]\n",
    "    with open(path_to_data,'r') as fid:\n",
    "        for lines in fid:\n",
    "            str_line = list(lines.strip().split(','))\n",
    "            \n",
    "            unq_line = list(set(str_line))\n",
    "            unq_line.sort()\n",
    "            for each_ele in unq_line:\n",
    "                order.append(each_ele)\n",
    "            Transactions.append(unq_line)\n",
    "        order=list(set(order))\n",
    "        order.sort()\n",
    "    return Transactions,order\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order\n",
      "\n",
      " ['Bed Skirts', 'Bedding Collections', 'Bedspreads', 'Decorative Pillows', 'Embroidered Bedspread', 'Kids Bedding', 'Quilts', 'Shams', 'Sheets']\n",
      "\n",
      "Transactions\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Decorative Pillows', 'Embroidered Bedspread', 'Quilts'],\n",
       " ['Bed Skirts',\n",
       "  'Bedding Collections',\n",
       "  'Bedspreads',\n",
       "  'Embroidered Bedspread',\n",
       "  'Kids Bedding',\n",
       "  'Shams',\n",
       "  'Sheets'],\n",
       " ['Bedding Collections',\n",
       "  'Decorative Pillows',\n",
       "  'Embroidered Bedspread',\n",
       "  'Kids Bedding',\n",
       "  'Quilts',\n",
       "  'Shams'],\n",
       " ['Bed Skirts', 'Bedding Collections', 'Bedspreads', 'Kids Bedding', 'Sheets'],\n",
       " ['Bed Skirts',\n",
       "  'Bedding Collections',\n",
       "  'Bedspreads',\n",
       "  'Decorative Pillows',\n",
       "  'Kids Bedding',\n",
       "  'Sheets'],\n",
       " ['Bed Skirts',\n",
       "  'Bedding Collections',\n",
       "  'Bedspreads',\n",
       "  'Kids Bedding',\n",
       "  'Shams',\n",
       "  'Sheets'],\n",
       " ['Decorative Pillows', 'Quilts'],\n",
       " ['Decorative Pillows', 'Embroidered Bedspread', 'Quilts'],\n",
       " ['Bed Skirts', 'Bedspreads', 'Kids Bedding', 'Shams', 'Sheets'],\n",
       " ['Bedding Collections', 'Embroidered Bedspread', 'Quilts'],\n",
       " ['Bed Skirts',\n",
       "  'Bedding Collections',\n",
       "  'Bedspreads',\n",
       "  'Kids Bedding',\n",
       "  'Shams',\n",
       "  'Sheets'],\n",
       " ['Decorative Pillows', 'Quilts'],\n",
       " ['Embroidered Bedspread', 'Shams'],\n",
       " ['Bed Skirts', 'Kids Bedding', 'Shams', 'Sheets'],\n",
       " ['Decorative Pillows', 'Quilts'],\n",
       " ['Bed Skirts', 'Decorative Pillows', 'Kids Bedding', 'Shams'],\n",
       " ['Bed Skirts', 'Decorative Pillows', 'Shams'],\n",
       " ['Kids Bedding', 'Quilts', 'Sheets'],\n",
       " ['Bed Skirts', 'Kids Bedding', 'Shams', 'Sheets'],\n",
       " ['Bed Skirts',\n",
       "  'Bedspreads',\n",
       "  'Decorative Pillows',\n",
       "  'Kids Bedding',\n",
       "  'Shams',\n",
       "  'Sheets']]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd=load_transactions(path_to_data)\n",
    "Transactions=pd[0]\n",
    "order=pd[1]\n",
    "num_trans = len(Transactions)\n",
    "print('order\\n\\n',order)\n",
    "print('\\nTransactions\\n')\n",
    "Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating itemset-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "C={}\n",
    "L={}\n",
    "itemset_size=1\n",
    "\n",
    "Discarded = {itemset_size:[]}\n",
    "C.update({itemset_size : [[f] for f in order]})\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurences(itemset,Transactions):\n",
    "    count=0\n",
    "    for i in range(len(Transactions)):\n",
    "        if set(itemset).issubset(set(Transactions[i])):\n",
    "            count+=1\n",
    "            \n",
    "    return count         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent(itemsets,Tansactions,min_support,prev_discarded):\n",
    "    L=[]\n",
    "    supp_count=[]\n",
    "    new_discarded=[]\n",
    "    num_trans= len(Transactions)\n",
    "    \n",
    "    k= len(prev_discarded.keys())\n",
    "    \n",
    "    for s in range(len(itemsets)):\n",
    "        discarded_before = False\n",
    "        if k>0:\n",
    "            for it in prev_discarded[k]:\n",
    "                if set(it).issubset(set(itemsets[s])):\n",
    "                    discarded_before=True\n",
    "                    break\n",
    "                    \n",
    "        if not discarded_before:\n",
    "            count=count_occurences(itemsets[s],Transactions)\n",
    "            if count/num_trans >= min_support:\n",
    "                L.append(itemsets[s])\n",
    "                supp_count.append(count)\n",
    "            else:\n",
    "                new_discarded.append(itemsets[s])\n",
    "                \n",
    "    return L,supp_count,new_discarded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_count_L={}\n",
    "f,sup,new_discarded=get_frequent(C[itemset_size],Transactions,min_support,Discarded)\n",
    "Discarded.update({itemset_size : new_discarded})\n",
    "L.update({itemset_size : f})\n",
    "supp_count_L.update({itemset_size:sup})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for Printing Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(T,supp_count):\n",
    "    print(\"Itemset | Frequency\")\n",
    "    for k in range(len(T)):\n",
    "        print(\"{} : {}\".format(T[k],supp_count[k]))\n",
    "    print(\"\\n\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itemset | Frequency\n",
      "['Bed Skirts'] : 11\n",
      "['Decorative Pillows'] : 10\n",
      "['Kids Bedding'] : 12\n",
      "['Quilts'] : 8\n",
      "['Shams'] : 11\n",
      "['Sheets'] : 10\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_table(L[1],supp_count_L[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating itemset-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_two_itemsets(it1,it2,order):\n",
    "    it1.sort(key=lambda x:order.index(x))\n",
    "    it2.sort(key=lambda x:order.index(x))\n",
    "    \n",
    "    for i in range(len(it1)-1):\n",
    "        if it1[i] != it2[i]:\n",
    "            return []\n",
    "    \n",
    "        \n",
    "    if order.index(it1[-1]) < order.index(it2[-1]):\n",
    "        return it1 + [it2[-1]]\n",
    "    \n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_itemsets(set_of_its,order):\n",
    "    c=[]\n",
    "    for i in range(len(set_of_its)):\n",
    "        for j in range(i+1,len(set_of_its)):\n",
    "            it_out = join_two_itemsets(set_of_its[i],set_of_its[j],order)\n",
    "            if len(it_out) >0:\n",
    "                c.append(it_out)\n",
    "                \n",
    "    return c             \n",
    "                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table c2: \n",
      "\n",
      "Itemset | Frequency\n",
      "['Bed Skirts', 'Decorative Pillows'] : 4\n",
      "['Bed Skirts', 'Kids Bedding'] : 10\n",
      "['Bed Skirts', 'Quilts'] : 0\n",
      "['Bed Skirts', 'Shams'] : 9\n",
      "['Bed Skirts', 'Sheets'] : 9\n",
      "['Decorative Pillows', 'Kids Bedding'] : 4\n",
      "['Decorative Pillows', 'Quilts'] : 6\n",
      "['Decorative Pillows', 'Shams'] : 4\n",
      "['Decorative Pillows', 'Sheets'] : 2\n",
      "['Kids Bedding', 'Quilts'] : 2\n",
      "['Kids Bedding', 'Shams'] : 9\n",
      "['Kids Bedding', 'Sheets'] : 10\n",
      "['Quilts', 'Shams'] : 1\n",
      "['Quilts', 'Sheets'] : 1\n",
      "['Shams', 'Sheets'] : 7\n",
      "\n",
      "\n",
      "\n",
      "Table L2: \n",
      "\n",
      "Itemset | Frequency\n",
      "['Bed Skirts', 'Kids Bedding'] : 10\n",
      "['Bed Skirts', 'Shams'] : 9\n",
      "['Bed Skirts', 'Sheets'] : 9\n",
      "['Kids Bedding', 'Shams'] : 9\n",
      "['Kids Bedding', 'Sheets'] : 10\n",
      "\n",
      "\n",
      "\n",
      "Table c3: \n",
      "\n",
      "Itemset | Frequency\n",
      "['Bed Skirts', 'Kids Bedding', 'Shams'] : 8\n",
      "['Bed Skirts', 'Kids Bedding', 'Sheets'] : 9\n",
      "['Bed Skirts', 'Shams', 'Sheets'] : 7\n",
      "['Kids Bedding', 'Shams', 'Sheets'] : 7\n",
      "\n",
      "\n",
      "\n",
      "Table L3: \n",
      "\n",
      "Itemset | Frequency\n",
      "['Bed Skirts', 'Kids Bedding', 'Shams'] : 8\n",
      "['Bed Skirts', 'Kids Bedding', 'Sheets'] : 9\n",
      "\n",
      "\n",
      "\n",
      "Table c4: \n",
      "\n",
      "Itemset | Frequency\n",
      "['Bed Skirts', 'Kids Bedding', 'Shams', 'Sheets'] : 7\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k=itemset_size+1\n",
    "convergence =False\n",
    "while not convergence:\n",
    "    C.update({k : join_itemsets(L[k-1],order)})\n",
    "    \n",
    "    print(\"Table c{}: \\n\".format(k))\n",
    "    print_table(C[k],[count_occurences(it,Transactions) for it in C[k]])\n",
    "    f,sup,new_discarded=get_frequent(C[k],Transactions,min_support,Discarded)\n",
    "    Discarded.update({k:new_discarded})\n",
    "    L.update({k:f})\n",
    "    supp_count_L.update({k:sup})\n",
    "    if len(L[k]) ==0:\n",
    "        convergence=True\n",
    "    else:\n",
    "        print(\"Table L{}: \\n\".format(k))\n",
    "        print_table(L[k],supp_count_L[k])\n",
    "    k+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Association Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations,chain\n",
    "def powerset(s):\n",
    "    return list(chain.from_iterable(combinations(s,r) for r in range(1,len(s)+1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_rules(X,X_S,S,conf,supp,num_tran):\n",
    "    out_rules = \"\"\n",
    "    out_rules += \"Frequent Itemset: {}\\n\".format(X)\n",
    "    out_rules +=\"     Rule: {} -> {} \\n\".format(list(S),list(X_S)) \n",
    "    out_rules +=\"     Confidence: {0:2.3f}\".format(conf)\n",
    "    out_rules +=\"     Support: {0:2.3f}\\n\".format(supp/num_trans)\n",
    "    return out_rules\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_rules_str = \"\"\n",
    "for i in range(1,len(L)):\n",
    "    for j in range(len(L[i])):\n",
    "        s = powerset(L[i][j])\n",
    "        s.pop()\n",
    "        \n",
    "        for z in s:\n",
    "            S = set(z)\n",
    "            X = set(L[i][j])\n",
    "            X_S = set(X-S)\n",
    "            sup_x = count_occurences(X,Transactions)\n",
    "            sup_x_s = count_occurences(X_S,Transactions)\n",
    "            conf = sup_x / count_occurences(S,Transactions)\n",
    "            if conf >= min_confidence and sup_x >= min_support:\n",
    "                assoc_rules_str += write_rules(X,X_S,S,conf,sup_x,num_trans)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemset: {'Kids Bedding', 'Sheets'}\n",
      "     Rule: ['Sheets'] -> ['Kids Bedding'] \n",
      "     Confidence: 1.000     Support: 0.500\n",
      "Frequent Itemset: {'Kids Bedding', 'Bed Skirts', 'Sheets'}\n",
      "     Rule: ['Bed Skirts', 'Sheets'] -> ['Kids Bedding'] \n",
      "     Confidence: 1.000     Support: 0.450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(assoc_rules_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
